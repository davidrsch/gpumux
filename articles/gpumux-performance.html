<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Advanced Usage: Worker Types and Performance Trade-offs • gpumux</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png">
<link rel="icon" type="”image/svg+xml”" href="../favicon.svg">
<link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
<link rel="icon" sizes="any" href="../favicon.ico">
<link rel="manifest" href="../site.webmanifest">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Advanced Usage: Worker Types and Performance Trade-offs">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">gpumux</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/gpumux-performance.html">Advanced Usage: Worker Types and Performance Trade-offs</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Advanced Usage: Worker Types and Performance Trade-offs</h1>
            
      

      <div class="d-none name"><code>gpumux-performance.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p><code>gpumux</code> offers two distinct worker types,
<code>"persistent"</code> and <code>"proxy"</code>, each with its own
performance characteristics and stability guarantees. This vignette
explores the difference between them and provides guidance on which to
choose for your workload.</p>
<ul>
<li><p><strong><code>persistent</code> (Default):</strong> This worker
type creates long-lived R sessions that persist between tasks. It offers
the highest performance because it avoids the overhead of starting a new
R process for each computation. It is ideal for tasks that are
well-behaved and manage their own GPU memory effectively.</p></li>
<li><p><strong><code>proxy</code>:</strong> This worker type creates a
lightweight “proxy” daemon that, in turn, spawns a completely new,
ephemeral R process for every single task. This provides the ultimate
stability and guarantees that all resources (including VRAM) are
released back to the OS after the task is complete. It is the perfect
solution for preventing memory leaks from frameworks like TensorFlow or
PyTorch, but it incurs a performance penalty due to process startup
overhead.</p></li>
</ul>
<p>To run this benchmark, you will need the <code>tensorflow</code> and
<code>processx</code> packages installed, along with a CUDA-enabled
NVIDIA GPU.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va">gpumux</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://mirai.r-lib.org" class="external-link">mirai</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/rstudio/tensorflow" class="external-link">tensorflow</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/joshuaulrich/microbenchmark/" class="external-link">microbenchmark</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://purrr.tidyverse.org/" class="external-link">purrr</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Check if a GPU is available</span></span>
<span><span class="va">gpu_devices</span> <span class="op">&lt;-</span> <span class="fu">gpumux</span><span class="fu">::</span><span class="fu"><a href="../reference/list_gpus.html">list_gpus</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">can_run_benchmark</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">gpu_devices</span><span class="op">)</span> <span class="op">&gt;</span> <span class="fl">0</span></span>
<span><span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="va">can_run_benchmark</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/message.html" class="external-link">message</a></span><span class="op">(</span><span class="st">"No GPU devices detected. Skipping benchmark."</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="task-definitions">Task Definitions<a class="anchor" aria-label="anchor" href="#task-definitions"></a>
</h2>
<p>To illustrate the performance trade-offs, we will define three types
of tasks:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Heavy Task:</strong> A large matrix multiplication
(<code>2048x2048</code>) designed to saturate the GPU.</li>
<li>
<strong>Medium Task:</strong> A smaller matrix multiplication
(<code>1024x1024</code>) that should not saturate the GPU.</li>
<li>
<strong>Light Task:</strong> A trivial operation that returns
instantly to highlight overhead.</li>
</ol>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># 1. Heavy Task: Large matrix multiplication</span></span>
<span><span class="va">heavy_task</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">device</span> <span class="op">=</span> <span class="st">"gpu"</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/rstudio/tensorflow" class="external-link">tensorflow</a></span><span class="op">)</span></span>
<span>  <span class="va">device_str</span> <span class="op">&lt;-</span> <span class="kw">if</span> <span class="op">(</span><span class="va">device</span> <span class="op">==</span> <span class="st">"gpu"</span><span class="op">)</span> <span class="st">"/gpu:0"</span> <span class="kw">else</span> <span class="st">"/cpu:0"</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/with.html" class="external-link">with</a></span><span class="op">(</span><span class="va">tf</span><span class="op">$</span><span class="fu">device</span><span class="op">(</span><span class="va">device_str</span><span class="op">)</span>, <span class="op">{</span></span>
<span>    <span class="va">x</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="va">random</span><span class="op">$</span><span class="fu">normal</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="fl">2048</span>, <span class="fl">2048</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="va">y</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="va">linalg</span><span class="op">$</span><span class="fu">matmul</span><span class="op">(</span><span class="va">x</span>, <span class="va">x</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="va">tf</span><span class="op">$</span><span class="fu">reduce_sum</span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">}</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># 2. Medium-Workload Task</span></span>
<span><span class="va">medium_task</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">device</span> <span class="op">=</span> <span class="st">"gpu"</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/rstudio/tensorflow" class="external-link">tensorflow</a></span><span class="op">)</span></span>
<span>  <span class="va">device_str</span> <span class="op">&lt;-</span> <span class="kw">if</span> <span class="op">(</span><span class="va">device</span> <span class="op">==</span> <span class="st">"gpu"</span><span class="op">)</span> <span class="st">"/gpu:0"</span> <span class="kw">else</span> <span class="st">"/cpu:0"</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/with.html" class="external-link">with</a></span><span class="op">(</span><span class="va">tf</span><span class="op">$</span><span class="fu">device</span><span class="op">(</span><span class="va">device_str</span><span class="op">)</span>, <span class="op">{</span></span>
<span>    <span class="va">x</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="va">random</span><span class="op">$</span><span class="fu">normal</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="fl">1024</span>, <span class="fl">1024</span><span class="op">)</span><span class="op">)</span> <span class="co"># Smaller matrix</span></span>
<span>    <span class="va">y</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="va">linalg</span><span class="op">$</span><span class="fu">matmul</span><span class="op">(</span><span class="va">x</span>, <span class="va">x</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="va">tf</span><span class="op">$</span><span class="fu">reduce_sum</span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">}</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># 3. Light Task: Returns a simple value instantly</span></span>
<span><span class="va">light_task</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Sys.time.html" class="external-link">Sys.time</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="benchmark-1-gpu-saturating-tasks-the-stress-test">Benchmark 1: GPU-Saturating Tasks (The “Stress Test”)<a class="anchor" aria-label="anchor" href="#benchmark-1-gpu-saturating-tasks-the-stress-test"></a>
</h2>
<p>This first benchmark uses the <strong>heavy task</strong>. It
represents a “worst-case” scenario for parallelism, where tasks compete
heavily for the same hardware.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Function to add total time to summary</span></span>
<span><span class="va">summary_with_total</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">bench_data</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">summary_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">bench_data</span><span class="op">)</span></span>
<span>  <span class="va">total_time_ns</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">bench_data</span><span class="op">$</span><span class="va">time</span><span class="op">)</span></span>
<span>  <span class="va">summary_df</span><span class="op">$</span><span class="va">total_time</span> <span class="op">&lt;-</span> <span class="va">total_time_ns</span> <span class="op">/</span> <span class="fl">1e9</span> </span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="va">summary_df</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># --- 1. Persistent Worker Benchmark (Heavy) ---</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/message.html" class="external-link">message</a></span><span class="op">(</span><span class="st">"Running HEAVY benchmark with 'persistent' workers..."</span><span class="op">)</span></span>
<span><span class="fu">gpumux</span><span class="fu">::</span><span class="fu"><a href="../reference/gpu_daemons.html">gpu_daemons</a></span><span class="op">(</span></span>
<span>  n_workers <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  gpu_ids <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  memory_per_worker_mb <span class="op">=</span> <span class="fl">1024</span>,</span>
<span>  framework <span class="op">=</span> <span class="st">"tensorflow"</span>,</span>
<span>  worker_type <span class="op">=</span> <span class="st">"persistent"</span></span>
<span><span class="op">)</span></span>
<span><span class="va">persistent_heavy_bench</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/microbenchmark/man/microbenchmark.html" class="external-link">microbenchmark</a></span><span class="op">(</span></span>
<span>  <span class="st">"Persistent - Heavy"</span> <span class="op">=</span> <span class="op">{</span></span>
<span>    <span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="st">"gpu"</span>, <span class="fl">4</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>      <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html" class="external-link">map</a></span><span class="op">(</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/in_parallel.html" class="external-link">in_parallel</a></span><span class="op">(</span>\<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu">heavy_task</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, heavy_task <span class="op">=</span> <span class="va">heavy_task</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="va">results</span></span>
<span>  <span class="op">}</span>,</span>
<span>  times <span class="op">=</span> <span class="fl">5L</span>,</span>
<span>  unit <span class="op">=</span> <span class="st">"seconds"</span></span>
<span><span class="op">)</span></span>
<span><span class="fu">gpumux</span><span class="fu">::</span><span class="fu"><a href="../reference/gpu_daemons.html">gpu_daemons</a></span><span class="op">(</span>n_workers <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Sys.sleep.html" class="external-link">Sys.sleep</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># --- 2. Proxy Worker Benchmark (Heavy) ---</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/message.html" class="external-link">message</a></span><span class="op">(</span><span class="st">"Running HEAVY benchmark with 'proxy' workers..."</span><span class="op">)</span></span>
<span><span class="fu">gpumux</span><span class="fu">::</span><span class="fu"><a href="../reference/gpu_daemons.html">gpu_daemons</a></span><span class="op">(</span></span>
<span>  n_workers <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  gpu_ids <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  memory_per_worker_mb <span class="op">=</span> <span class="fl">1024</span>,</span>
<span>  framework <span class="op">=</span> <span class="st">"tensorflow"</span>,</span>
<span>  worker_type <span class="op">=</span> <span class="st">"proxy"</span></span>
<span><span class="op">)</span></span>
<span><span class="va">proxy_heavy_bench</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/microbenchmark/man/microbenchmark.html" class="external-link">microbenchmark</a></span><span class="op">(</span></span>
<span>  <span class="st">"Proxy - Heavy"</span> <span class="op">=</span> <span class="op">{</span></span>
<span>    <span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="st">"gpu"</span>, <span class="fl">4</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>      <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html" class="external-link">map</a></span><span class="op">(</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/in_parallel.html" class="external-link">in_parallel</a></span><span class="op">(</span>\<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu">heavy_task</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, heavy_task <span class="op">=</span> <span class="va">heavy_task</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="va">results</span></span>
<span>  <span class="op">}</span>,</span>
<span>  times <span class="op">=</span> <span class="fl">5L</span>,</span>
<span>  unit <span class="op">=</span> <span class="st">"seconds"</span></span>
<span><span class="op">)</span></span>
<span><span class="fu">gpumux</span><span class="fu">::</span><span class="fu"><a href="../reference/gpu_daemons.html">gpu_daemons</a></span><span class="op">(</span>n_workers <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Sys.sleep.html" class="external-link">Sys.sleep</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># --- 3. Sequential GPU Benchmark (Heavy) ---</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/message.html" class="external-link">message</a></span><span class="op">(</span><span class="st">"Running HEAVY benchmark with 'Sequential GPU' (via single worker)..."</span><span class="op">)</span></span>
<span><span class="co"># By running the tasks on a single worker daemon, we simulate sequential</span></span>
<span><span class="co"># execution while still benefiting from the process isolation and automatic</span></span>
<span><span class="co"># cleanup that gpumux provides.</span></span>
<span><span class="fu">gpumux</span><span class="fu">::</span><span class="fu"><a href="../reference/gpu_daemons.html">gpu_daemons</a></span><span class="op">(</span></span>
<span>  n_workers <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  gpu_ids <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  memory_per_worker_mb <span class="op">=</span> <span class="fl">1024</span>,</span>
<span>  framework <span class="op">=</span> <span class="st">"tensorflow"</span>,</span>
<span>  worker_type <span class="op">=</span> <span class="st">"persistent"</span></span>
<span><span class="op">)</span></span>
<span><span class="va">sequential_gpu_heavy_bench</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/microbenchmark/man/microbenchmark.html" class="external-link">microbenchmark</a></span><span class="op">(</span></span>
<span>  <span class="st">"Sequential GPU - Heavy"</span> <span class="op">=</span> <span class="op">{</span></span>
<span>    <span class="co"># With only one worker, these 4 tasks will be processed sequentially.</span></span>
<span>    <span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="st">"gpu"</span>, <span class="fl">4</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>      <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html" class="external-link">map</a></span><span class="op">(</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/in_parallel.html" class="external-link">in_parallel</a></span><span class="op">(</span>\<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu">heavy_task</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, heavy_task <span class="op">=</span> <span class="va">heavy_task</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="va">results</span></span>
<span>  <span class="op">}</span>,</span>
<span>  times <span class="op">=</span> <span class="fl">5L</span>,</span>
<span>  unit <span class="op">=</span> <span class="st">"seconds"</span></span>
<span><span class="op">)</span></span>
<span><span class="fu">gpumux</span><span class="fu">::</span><span class="fu"><a href="../reference/gpu_daemons.html">gpu_daemons</a></span><span class="op">(</span>n_workers <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Sys.sleep.html" class="external-link">Sys.sleep</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># --- 4. CPU Benchmark (Heavy) ---</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/message.html" class="external-link">message</a></span><span class="op">(</span><span class="st">"Running HEAVY benchmark with 'CPU' workers..."</span><span class="op">)</span></span>
<span><span class="fu">mirai</span><span class="fu">::</span><span class="fu"><a href="https://mirai.r-lib.org/reference/daemons.html" class="external-link">daemons</a></span><span class="op">(</span><span class="fl">4</span><span class="op">)</span></span>
<span><span class="va">cpu_heavy_bench</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/microbenchmark/man/microbenchmark.html" class="external-link">microbenchmark</a></span><span class="op">(</span></span>
<span>  <span class="st">"CPU - Heavy"</span> <span class="op">=</span> <span class="op">{</span></span>
<span>    <span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="st">"cpu"</span>, <span class="fl">4</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>      <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html" class="external-link">map</a></span><span class="op">(</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/in_parallel.html" class="external-link">in_parallel</a></span><span class="op">(</span>\<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu">heavy_task</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, heavy_task <span class="op">=</span> <span class="va">heavy_task</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="va">results</span></span>
<span>  <span class="op">}</span>,</span>
<span>   times <span class="op">=</span> <span class="fl">5L</span>,</span>
<span>  unit <span class="op">=</span> <span class="st">"seconds"</span></span>
<span><span class="op">)</span></span>
<span><span class="fu">mirai</span><span class="fu">::</span><span class="fu"><a href="https://mirai.r-lib.org/reference/daemons.html" class="external-link">daemons</a></span><span class="op">(</span><span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># --- 5. Results (Heavy) ---</span></span>
<span><span class="va">heavy_benchmarks</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span></span>
<span>  <span class="fu">summary_with_total</span><span class="op">(</span><span class="va">persistent_heavy_bench</span><span class="op">)</span>,</span>
<span>  <span class="fu">summary_with_total</span><span class="op">(</span><span class="va">proxy_heavy_bench</span><span class="op">)</span>,</span>
<span>  <span class="fu">summary_with_total</span><span class="op">(</span><span class="va">sequential_gpu_heavy_bench</span><span class="op">)</span>,</span>
<span>  <span class="fu">summary_with_total</span><span class="op">(</span><span class="va">cpu_heavy_bench</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="fu">knitr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/knitr/man/kable.html" class="external-link">kable</a></span><span class="op">(</span><span class="va">heavy_benchmarks</span>, caption <span class="op">=</span> <span class="st">"GPU-Saturating Workload Results"</span><span class="op">)</span></span></code></pre></div>
<blockquote>
<p><strong>A Note on Memory Cleanup:</strong> You may notice that after
this benchmark, your VRAM is not fully cleared. The
<code>Sequential GPU - Heavy</code> run happens in the main R process.
TensorFlow is known to hold onto VRAM until the R session itself is
terminated. This is a perfect illustration of the resource management
problem <code>gpumux</code> solves. Because <code>gpumux</code> runs
tasks in separate daemon processes, it can guarantee that all resources
are released when the daemons are terminated.</p>
</blockquote>
</div>
<div class="section level2">
<h2 id="benchmark-2-non-saturating-gpu-tasks-the-sweet-spot">Benchmark 2: Non-Saturating GPU Tasks (The “Sweet Spot”)<a class="anchor" aria-label="anchor" href="#benchmark-2-non-saturating-gpu-tasks-the-sweet-spot"></a>
</h2>
<p>This benchmark uses the <strong>medium task</strong>. Because each
task doesn’t use 100% of the GPU, there is spare capacity for
<code>gpumux</code> to leverage.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># --- 1. Persistent Worker Benchmark (Medium) ---</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/message.html" class="external-link">message</a></span><span class="op">(</span><span class="st">"Running MEDIUM benchmark with 'persistent' workers..."</span><span class="op">)</span></span>
<span><span class="fu">gpumux</span><span class="fu">::</span><span class="fu"><a href="../reference/gpu_daemons.html">gpu_daemons</a></span><span class="op">(</span></span>
<span>  n_workers <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  gpu_ids <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  memory_per_worker_mb <span class="op">=</span> <span class="fl">1024</span>,</span>
<span>  framework <span class="op">=</span> <span class="st">"tensorflow"</span>,</span>
<span>  worker_type <span class="op">=</span> <span class="st">"persistent"</span></span>
<span><span class="op">)</span></span>
<span><span class="va">persistent_medium_bench</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/microbenchmark/man/microbenchmark.html" class="external-link">microbenchmark</a></span><span class="op">(</span></span>
<span>  <span class="st">"Persistent - Medium"</span> <span class="op">=</span> <span class="op">{</span></span>
<span>    <span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="st">"gpu"</span>, <span class="fl">4</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>      <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html" class="external-link">map</a></span><span class="op">(</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/in_parallel.html" class="external-link">in_parallel</a></span><span class="op">(</span>\<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu">medium_task</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, medium_task <span class="op">=</span> <span class="va">medium_task</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="va">results</span></span>
<span>  <span class="op">}</span>,</span>
<span>  times <span class="op">=</span> <span class="fl">10L</span>,</span>
<span>  unit <span class="op">=</span> <span class="st">"seconds"</span></span>
<span><span class="op">)</span></span>
<span><span class="fu">gpumux</span><span class="fu">::</span><span class="fu"><a href="../reference/gpu_daemons.html">gpu_daemons</a></span><span class="op">(</span>n_workers <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Sys.sleep.html" class="external-link">Sys.sleep</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># --- 2. Proxy Worker Benchmark (Medium) ---</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/message.html" class="external-link">message</a></span><span class="op">(</span><span class="st">"Running MEDIUM benchmark with 'proxy' workers..."</span><span class="op">)</span></span>
<span><span class="fu">gpumux</span><span class="fu">::</span><span class="fu"><a href="../reference/gpu_daemons.html">gpu_daemons</a></span><span class="op">(</span></span>
<span>  n_workers <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  gpu_ids <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  memory_per_worker_mb <span class="op">=</span> <span class="fl">1024</span>,</span>
<span>  framework <span class="op">=</span> <span class="st">"tensorflow"</span>,</span>
<span>  worker_type <span class="op">=</span> <span class="st">"proxy"</span></span>
<span><span class="op">)</span></span>
<span><span class="va">proxy_medium_bench</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/microbenchmark/man/microbenchmark.html" class="external-link">microbenchmark</a></span><span class="op">(</span></span>
<span>  <span class="st">"Proxy - Medium"</span> <span class="op">=</span> <span class="op">{</span></span>
<span>    <span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="st">"gpu"</span>, <span class="fl">4</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>      <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html" class="external-link">map</a></span><span class="op">(</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/in_parallel.html" class="external-link">in_parallel</a></span><span class="op">(</span>\<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu">medium_task</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, medium_task <span class="op">=</span> <span class="va">medium_task</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="va">results</span></span>
<span>  <span class="op">}</span>,</span>
<span>  times <span class="op">=</span> <span class="fl">10L</span>,</span>
<span>  unit <span class="op">=</span> <span class="st">"seconds"</span></span>
<span><span class="op">)</span></span>
<span><span class="fu">gpumux</span><span class="fu">::</span><span class="fu"><a href="../reference/gpu_daemons.html">gpu_daemons</a></span><span class="op">(</span>n_workers <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Sys.sleep.html" class="external-link">Sys.sleep</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># --- 3. Sequential GPU Benchmark (Medium) ---</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/message.html" class="external-link">message</a></span><span class="op">(</span><span class="st">"Running MEDIUM benchmark with 'Sequential GPU' (via single worker)..."</span><span class="op">)</span></span>
<span><span class="fu">gpumux</span><span class="fu">::</span><span class="fu"><a href="../reference/gpu_daemons.html">gpu_daemons</a></span><span class="op">(</span></span>
<span>  n_workers <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  gpu_ids <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  memory_per_worker_mb <span class="op">=</span> <span class="fl">1024</span>,</span>
<span>  framework <span class="op">=</span> <span class="st">"tensorflow"</span>,</span>
<span>  worker_type <span class="op">=</span> <span class="st">"persistent"</span></span>
<span><span class="op">)</span></span>
<span><span class="va">sequential_medium_bench</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/microbenchmark/man/microbenchmark.html" class="external-link">microbenchmark</a></span><span class="op">(</span></span>
<span>  <span class="st">"Sequential GPU - Medium"</span> <span class="op">=</span> <span class="op">{</span></span>
<span>    <span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="st">"gpu"</span>, <span class="fl">4</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>      <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html" class="external-link">map</a></span><span class="op">(</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/in_parallel.html" class="external-link">in_parallel</a></span><span class="op">(</span>\<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu">medium_task</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, medium_task <span class="op">=</span> <span class="va">medium_task</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="va">results</span></span>
<span>  <span class="op">}</span>,</span>
<span>  times <span class="op">=</span> <span class="fl">10L</span>,</span>
<span>  unit <span class="op">=</span> <span class="st">"seconds"</span></span>
<span><span class="op">)</span></span>
<span><span class="fu">gpumux</span><span class="fu">::</span><span class="fu"><a href="../reference/gpu_daemons.html">gpu_daemons</a></span><span class="op">(</span>n_workers <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Sys.sleep.html" class="external-link">Sys.sleep</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># --- 4. CPU Benchmark (Medium) ---</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/message.html" class="external-link">message</a></span><span class="op">(</span><span class="st">"Running MEDIUM benchmark with 'CPU' workers..."</span><span class="op">)</span></span>
<span><span class="fu">mirai</span><span class="fu">::</span><span class="fu"><a href="https://mirai.r-lib.org/reference/daemons.html" class="external-link">daemons</a></span><span class="op">(</span><span class="fl">4</span><span class="op">)</span></span>
<span><span class="va">cpu_medium_bench</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/microbenchmark/man/microbenchmark.html" class="external-link">microbenchmark</a></span><span class="op">(</span></span>
<span>  <span class="st">"CPU - Medium"</span> <span class="op">=</span> <span class="op">{</span></span>
<span>    <span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="st">"cpu"</span>, <span class="fl">0</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>      <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html" class="external-link">map</a></span><span class="op">(</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/in_parallel.html" class="external-link">in_parallel</a></span><span class="op">(</span>\<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu">medium_task</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, medium_task <span class="op">=</span> <span class="va">medium_task</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="va">results</span></span>
<span>  <span class="op">}</span>,</span>
<span>  times <span class="op">=</span> <span class="fl">10L</span>,</span>
<span>  unit <span class="op">=</span> <span class="st">"seconds"</span></span>
<span><span class="op">)</span></span>
<span><span class="fu">mirai</span><span class="fu">::</span><span class="fu"><a href="https://mirai.r-lib.org/reference/daemons.html" class="external-link">daemons</a></span><span class="op">(</span><span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># --- 5. Results (Medium) ---</span></span>
<span><span class="va">medium_benchmarks</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span></span>
<span>  <span class="fu">summary_with_total</span><span class="op">(</span><span class="va">persistent_medium_bench</span><span class="op">)</span>,</span>
<span>  <span class="fu">summary_with_total</span><span class="op">(</span><span class="va">proxy_medium_bench</span><span class="op">)</span>,</span>
<span>  <span class="fu">summary_with_total</span><span class="op">(</span><span class="va">sequential_medium_bench</span><span class="op">)</span>,</span>
<span>  <span class="fu">summary_with_total</span><span class="op">(</span><span class="va">cpu_medium_bench</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="fu">knitr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/knitr/man/kable.html" class="external-link">kable</a></span><span class="op">(</span><span class="va">medium_benchmarks</span>, caption <span class="op">=</span> <span class="st">"Non-Saturating Workload Results"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="benchmark-3-trivial-tasks-the-overhead-test">Benchmark 3: Trivial Tasks (The “Overhead Test”)<a class="anchor" aria-label="anchor" href="#benchmark-3-trivial-tasks-the-overhead-test"></a>
</h2>
<p>Finally, this benchmark uses the <strong>light task</strong> to
isolate and measure the raw overhead of the different execution
methods.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># --- 1. Persistent Worker Benchmark (Light) ---</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/message.html" class="external-link">message</a></span><span class="op">(</span><span class="st">"Running LIGHT benchmark with 'persistent' workers..."</span><span class="op">)</span></span>
<span><span class="fu">gpumux</span><span class="fu">::</span><span class="fu"><a href="../reference/gpu_daemons.html">gpu_daemons</a></span><span class="op">(</span></span>
<span>  n_workers <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  gpu_ids <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  memory_per_worker_mb <span class="op">=</span> <span class="fl">1024</span>,</span>
<span>  framework <span class="op">=</span> <span class="st">"tensorflow"</span>,</span>
<span>  worker_type <span class="op">=</span> <span class="st">"persistent"</span></span>
<span><span class="op">)</span></span>
<span><span class="va">persistent_light_bench</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/microbenchmark/man/microbenchmark.html" class="external-link">microbenchmark</a></span><span class="op">(</span></span>
<span>  <span class="st">"Persistent - Light"</span> <span class="op">=</span> <span class="op">{</span></span>
<span>    <span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="st">"gpu"</span>, <span class="fl">4</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>      <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html" class="external-link">map</a></span><span class="op">(</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/in_parallel.html" class="external-link">in_parallel</a></span><span class="op">(</span>\<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu">light_task</span><span class="op">(</span><span class="op">)</span>, light_task <span class="op">=</span> <span class="va">light_task</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="va">results</span></span>
<span>  <span class="op">}</span>,</span>
<span>  times <span class="op">=</span> <span class="fl">20L</span>,</span>
<span>  unit <span class="op">=</span> <span class="st">"seconds"</span></span>
<span><span class="op">)</span></span>
<span><span class="fu">gpumux</span><span class="fu">::</span><span class="fu"><a href="../reference/gpu_daemons.html">gpu_daemons</a></span><span class="op">(</span>n_workers <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Sys.sleep.html" class="external-link">Sys.sleep</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># --- 2. Proxy Worker Benchmark (Light) ---</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/message.html" class="external-link">message</a></span><span class="op">(</span><span class="st">"Running LIGHT benchmark with 'proxy' workers..."</span><span class="op">)</span></span>
<span><span class="fu">gpumux</span><span class="fu">::</span><span class="fu"><a href="../reference/gpu_daemons.html">gpu_daemons</a></span><span class="op">(</span></span>
<span>  n_workers <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  gpu_ids <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  memory_per_worker_mb <span class="op">=</span> <span class="fl">1024</span>,</span>
<span>  framework <span class="op">=</span> <span class="st">"tensorflow"</span>,</span>
<span>  worker_type <span class="op">=</span> <span class="st">"proxy"</span></span>
<span><span class="op">)</span></span>
<span><span class="va">proxy_light_bench</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/microbenchmark/man/microbenchmark.html" class="external-link">microbenchmark</a></span><span class="op">(</span></span>
<span>  <span class="st">"Proxy - Light"</span> <span class="op">=</span> <span class="op">{</span></span>
<span>    <span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="st">"gpu"</span>, <span class="fl">4</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>      <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html" class="external-link">map</a></span><span class="op">(</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/in_parallel.html" class="external-link">in_parallel</a></span><span class="op">(</span>\<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu">light_task</span><span class="op">(</span><span class="op">)</span>, light_task <span class="op">=</span> <span class="va">light_task</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="va">results</span></span>
<span>  <span class="op">}</span>,</span>
<span>  times <span class="op">=</span> <span class="fl">20L</span>,</span>
<span>  unit <span class="op">=</span> <span class="st">"seconds"</span></span>
<span><span class="op">)</span></span>
<span><span class="fu">gpumux</span><span class="fu">::</span><span class="fu"><a href="../reference/gpu_daemons.html">gpu_daemons</a></span><span class="op">(</span>n_workers <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Sys.sleep.html" class="external-link">Sys.sleep</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># --- 3. Sequential GPU Benchmark (Light) ---</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/message.html" class="external-link">message</a></span><span class="op">(</span><span class="st">"Running LIGHT benchmark with 'Sequential GPU' (via single worker)..."</span><span class="op">)</span></span>
<span><span class="fu">gpumux</span><span class="fu">::</span><span class="fu"><a href="../reference/gpu_daemons.html">gpu_daemons</a></span><span class="op">(</span></span>
<span>  n_workers <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  gpu_ids <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  memory_per_worker_mb <span class="op">=</span> <span class="fl">1024</span>,</span>
<span>  framework <span class="op">=</span> <span class="st">"tensorflow"</span>,</span>
<span>  worker_type <span class="op">=</span> <span class="st">"persistent"</span></span>
<span><span class="op">)</span></span>
<span><span class="va">sequential_light_bench</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/microbenchmark/man/microbenchmark.html" class="external-link">microbenchmark</a></span><span class="op">(</span></span>
<span>  <span class="st">"Sequential GPU - Light"</span> <span class="op">=</span> <span class="op">{</span></span>
<span>    <span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="st">"gpu"</span>, <span class="fl">4</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>      <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html" class="external-link">map</a></span><span class="op">(</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/in_parallel.html" class="external-link">in_parallel</a></span><span class="op">(</span>\<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu">light_task</span><span class="op">(</span><span class="op">)</span>, light_task <span class="op">=</span> <span class="va">light_task</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="va">results</span></span>
<span>  <span class="op">}</span>,</span>
<span>  times <span class="op">=</span> <span class="fl">20L</span>,</span>
<span>  unit <span class="op">=</span> <span class="st">"seconds"</span></span>
<span><span class="op">)</span></span>
<span><span class="fu">gpumux</span><span class="fu">::</span><span class="fu"><a href="../reference/gpu_daemons.html">gpu_daemons</a></span><span class="op">(</span>n_workers <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Sys.sleep.html" class="external-link">Sys.sleep</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># --- 4. CPU Benchmark (Light) ---</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/message.html" class="external-link">message</a></span><span class="op">(</span><span class="st">"Running LIGHT benchmark with 'CPU'..."</span><span class="op">)</span></span>
<span><span class="fu">mirai</span><span class="fu">::</span><span class="fu"><a href="https://mirai.r-lib.org/reference/daemons.html" class="external-link">daemons</a></span><span class="op">(</span><span class="fl">4</span><span class="op">)</span></span>
<span><span class="va">cpu_light_bench</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/microbenchmark/man/microbenchmark.html" class="external-link">microbenchmark</a></span><span class="op">(</span></span>
<span>  <span class="st">"CPU - Light"</span> <span class="op">=</span> <span class="op">{</span></span>
<span>    <span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="st">"cpu"</span>, <span class="fl">4</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>      <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html" class="external-link">map</a></span><span class="op">(</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/in_parallel.html" class="external-link">in_parallel</a></span><span class="op">(</span>\<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu">light_task</span><span class="op">(</span><span class="op">)</span>, light_task <span class="op">=</span> <span class="va">light_task</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="va">results</span></span>
<span>  <span class="op">}</span>,</span>
<span>  times <span class="op">=</span> <span class="fl">20L</span>,</span>
<span>  unit <span class="op">=</span> <span class="st">"seconds"</span></span>
<span><span class="op">)</span></span>
<span><span class="fu">mirai</span><span class="fu">::</span><span class="fu"><a href="https://mirai.r-lib.org/reference/daemons.html" class="external-link">daemons</a></span><span class="op">(</span><span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># --- 5. Results (Light) ---</span></span>
<span><span class="va">light_benchmarks</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span></span>
<span>  <span class="fu">summary_with_total</span><span class="op">(</span><span class="va">persistent_light_bench</span><span class="op">)</span>,</span>
<span>  <span class="fu">summary_with_total</span><span class="op">(</span><span class="va">proxy_light_bench</span><span class="op">)</span>,</span>
<span>  <span class="fu">summary_with_total</span><span class="op">(</span><span class="va">sequential_light_bench</span><span class="op">)</span>,</span>
<span>  <span class="fu">summary_with_total</span><span class="op">(</span><span class="va">cpu_light_bench</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="fu">knitr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/knitr/man/kable.html" class="external-link">kable</a></span><span class="op">(</span><span class="va">light_benchmarks</span>, caption <span class="op">=</span> <span class="st">"Light Workload (Overhead) Results"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="benchmark-4-oom-stability-test">Benchmark 4: OOM Stability Test<a class="anchor" aria-label="anchor" href="#benchmark-4-oom-stability-test"></a>
</h2>
<p>This benchmark uses the <code>oom_task</code> to simulate a memory
leak. We will use a fixed number of iterations designed to consume
approximately 3GB of VRAM, which should be enough to trigger an
Out-of-Memory (OOM) error on the stateful workers
(<code>persistent</code> and <code>sequential</code>) but not on the
stateless <code>proxy</code> worker.</p>
<p>This provides a direct, quantitative comparison of worker
stability.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># 4. OOM Task: Deliberately allocates memory in a loop to simulate a leak.</span></span>
<span><span class="va">oom_task</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">device</span> <span class="op">=</span> <span class="st">"gpu"</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/rstudio/tensorflow" class="external-link">tensorflow</a></span><span class="op">)</span></span>
<span>  <span class="va">device_str</span> <span class="op">&lt;-</span> <span class="kw">if</span> <span class="op">(</span><span class="va">device</span> <span class="op">==</span> <span class="st">"gpu"</span><span class="op">)</span> <span class="st">"/gpu:0"</span> <span class="kw">else</span> <span class="st">"/cpu:0"</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/with.html" class="external-link">with</a></span><span class="op">(</span><span class="va">tf</span><span class="op">$</span><span class="fu">device</span><span class="op">(</span><span class="va">device_str</span><span class="op">)</span>, <span class="op">{</span></span>
<span>    <span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq_len</a></span><span class="op">(</span><span class="fl">30</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="va">x</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="va">random</span><span class="op">$</span><span class="fu">normal</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="fl">2048</span>, <span class="fl">2048</span><span class="op">)</span><span class="op">)</span></span>
<span>      <span class="va">y</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="va">linalg</span><span class="op">$</span><span class="fu">matmul</span><span class="op">(</span><span class="va">x</span>, <span class="va">x</span><span class="op">)</span></span>
<span>      <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="va">tf</span><span class="op">$</span><span class="fu">reduce_sum</span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="op">}</span></span>
<span>  <span class="op">}</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># We will attempt to allocate ~3GB of VRAM (30 iterations * 100MB).</span></span>
<span></span>
<span><span class="co"># --- 1. Persistent Worker OOM Benchmark ---</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/message.html" class="external-link">message</a></span><span class="op">(</span><span class="st">"\n--- Running OOM Benchmark for 'persistent' worker ---\n"</span><span class="op">)</span></span>
<span><span class="va">persistent_oom_bench</span> <span class="op">&lt;-</span> <span class="kw"><a href="https://rdrr.io/r/base/conditions.html" class="external-link">tryCatch</a></span><span class="op">(</span><span class="op">{</span></span>
<span>  <span class="fu">gpumux</span><span class="fu">::</span><span class="fu"><a href="../reference/gpu_daemons.html">gpu_daemons</a></span><span class="op">(</span></span>
<span>    n_workers <span class="op">=</span> <span class="fl">4</span>,</span>
<span>    gpu_ids <span class="op">=</span> <span class="fl">0</span>,</span>
<span>    memory_per_worker_mb <span class="op">=</span> <span class="fl">1024</span>,</span>
<span>    framework <span class="op">=</span> <span class="st">"tensorflow"</span>,</span>
<span>    worker_type <span class="op">=</span> <span class="st">"persistent"</span></span>
<span>  <span class="op">)</span></span>
<span>  <span class="va">bench</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/microbenchmark/man/microbenchmark.html" class="external-link">microbenchmark</a></span><span class="op">(</span></span>
<span>    <span class="st">"Persistent - OOM"</span> <span class="op">=</span> <span class="op">{</span></span>
<span>      <span class="co"># With only one worker, these 4 tasks will be processed sequentially.</span></span>
<span>      <span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="st">"gpu"</span>, <span class="fl">4</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>        <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html" class="external-link">map</a></span><span class="op">(</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/in_parallel.html" class="external-link">in_parallel</a></span><span class="op">(</span>\<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu">oom_task</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, oom_task <span class="op">=</span> <span class="va">oom_task</span><span class="op">)</span><span class="op">)</span></span>
<span>      <span class="va">results</span></span>
<span>    <span class="op">}</span>,</span>
<span>    times <span class="op">=</span> <span class="fl">5L</span>,</span>
<span>    unit <span class="op">=</span> <span class="st">"seconds"</span></span>
<span>  <span class="op">)</span></span>
<span>  <span class="fu">gpumux</span><span class="fu">::</span><span class="fu"><a href="../reference/gpu_daemons.html">gpu_daemons</a></span><span class="op">(</span>n_workers <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span>  <span class="va">summary_df</span> <span class="op">&lt;-</span> <span class="fu">summary_with_total</span><span class="op">(</span><span class="va">bench</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/Sys.sleep.html" class="external-link">Sys.sleep</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span></span>
<span>  <span class="va">summary_df</span></span>
<span><span class="op">}</span>, error <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">e</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/message.html" class="external-link">message</a></span><span class="op">(</span><span class="st">"Persistent worker failed as expected."</span><span class="op">)</span></span>
<span>  <span class="fu">gpumux</span><span class="fu">::</span><span class="fu"><a href="../reference/gpu_daemons.html">gpu_daemons</a></span><span class="op">(</span>n_workers <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/Sys.sleep.html" class="external-link">Sys.sleep</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>expr <span class="op">=</span> <span class="st">"Persistent - OOM"</span>, min <span class="op">=</span> <span class="cn">NA</span>, lq <span class="op">=</span> <span class="cn">NA</span>, mean <span class="op">=</span> <span class="cn">NA</span>, median <span class="op">=</span> <span class="cn">NA</span>, uq <span class="op">=</span> <span class="cn">NA</span>, max <span class="op">=</span> <span class="cn">NA</span>, neval <span class="op">=</span> <span class="fl">0</span>, total_time <span class="op">=</span> <span class="cn">NA</span><span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="co"># --- 2. Proxy Worker OOM Benchmark ---</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/message.html" class="external-link">message</a></span><span class="op">(</span><span class="st">"\n--- Running OOM Benchmark for 'proxy' worker ---\n"</span><span class="op">)</span></span>
<span><span class="va">proxy_oom_bench</span> <span class="op">&lt;-</span> <span class="kw"><a href="https://rdrr.io/r/base/conditions.html" class="external-link">tryCatch</a></span><span class="op">(</span><span class="op">{</span></span>
<span>  <span class="fu">gpumux</span><span class="fu">::</span><span class="fu"><a href="../reference/gpu_daemons.html">gpu_daemons</a></span><span class="op">(</span></span>
<span>    n_workers <span class="op">=</span> <span class="fl">4</span>,</span>
<span>    gpu_ids <span class="op">=</span> <span class="fl">0</span>,</span>
<span>    memory_per_worker_mb <span class="op">=</span> <span class="fl">1024</span>,</span>
<span>    framework <span class="op">=</span> <span class="st">"tensorflow"</span>,</span>
<span>    worker_type <span class="op">=</span> <span class="st">"proxy"</span></span>
<span>  <span class="op">)</span></span>
<span>  <span class="va">bench</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/microbenchmark/man/microbenchmark.html" class="external-link">microbenchmark</a></span><span class="op">(</span></span>
<span>    <span class="st">"Proxy - OOM"</span> <span class="op">=</span> <span class="op">{</span></span>
<span>      <span class="co"># With only one worker, these 4 tasks will be processed sequentially.</span></span>
<span>      <span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="st">"gpu"</span>, <span class="fl">4</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>        <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html" class="external-link">map</a></span><span class="op">(</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/in_parallel.html" class="external-link">in_parallel</a></span><span class="op">(</span>\<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu">oom_task</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, oom_task <span class="op">=</span> <span class="va">oom_task</span><span class="op">)</span><span class="op">)</span></span>
<span>      <span class="va">results</span></span>
<span>    <span class="op">}</span>,</span>
<span>    times <span class="op">=</span> <span class="fl">5L</span>,</span>
<span>    unit <span class="op">=</span> <span class="st">"seconds"</span></span>
<span>  <span class="op">)</span></span>
<span>  <span class="fu">gpumux</span><span class="fu">::</span><span class="fu"><a href="../reference/gpu_daemons.html">gpu_daemons</a></span><span class="op">(</span>n_workers <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span>  <span class="va">summary_df</span> <span class="op">&lt;-</span> <span class="fu">summary_with_total</span><span class="op">(</span><span class="va">bench</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/Sys.sleep.html" class="external-link">Sys.sleep</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span></span>
<span>  <span class="va">summary_df</span></span>
<span><span class="op">}</span>, error <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">e</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/message.html" class="external-link">message</a></span><span class="op">(</span><span class="st">"Proxy worker failed unexpectedly!"</span><span class="op">)</span></span>
<span>  <span class="fu">gpumux</span><span class="fu">::</span><span class="fu"><a href="../reference/gpu_daemons.html">gpu_daemons</a></span><span class="op">(</span>n_workers <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/Sys.sleep.html" class="external-link">Sys.sleep</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>expr <span class="op">=</span> <span class="st">"Proxy - OOM"</span>, min <span class="op">=</span> <span class="cn">NA</span>, lq <span class="op">=</span> <span class="cn">NA</span>, mean <span class="op">=</span> <span class="cn">NA</span>, median <span class="op">=</span> <span class="cn">NA</span>, uq <span class="op">=</span> <span class="cn">NA</span>, max <span class="op">=</span> <span class="cn">NA</span>, neval <span class="op">=</span> <span class="fl">0</span>, total_time <span class="op">=</span> <span class="cn">NA</span><span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="co"># --- 3. Sequential GPU OOM Benchmark ---</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/message.html" class="external-link">message</a></span><span class="op">(</span><span class="st">"\n--- Running OOM Benchmark for 'Sequential GPU' worker ---\n"</span><span class="op">)</span></span>
<span><span class="va">sequential_oom_bench</span> <span class="op">&lt;-</span> <span class="kw"><a href="https://rdrr.io/r/base/conditions.html" class="external-link">tryCatch</a></span><span class="op">(</span><span class="op">{</span></span>
<span>  <span class="fu">gpumux</span><span class="fu">::</span><span class="fu"><a href="../reference/gpu_daemons.html">gpu_daemons</a></span><span class="op">(</span></span>
<span>    n_workers <span class="op">=</span> <span class="fl">1</span>,</span>
<span>    gpu_ids <span class="op">=</span> <span class="fl">0</span>,</span>
<span>    memory_per_worker_mb <span class="op">=</span> <span class="fl">4096</span>,</span>
<span>    framework <span class="op">=</span> <span class="st">"tensorflow"</span>,</span>
<span>    worker_type <span class="op">=</span> <span class="st">"persistent"</span></span>
<span>  <span class="op">)</span></span>
<span>  <span class="va">bench</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/microbenchmark/man/microbenchmark.html" class="external-link">microbenchmark</a></span><span class="op">(</span></span>
<span>    <span class="st">"Sequential GPU - OOM"</span> <span class="op">=</span> <span class="op">{</span></span>
<span>      <span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="st">"gpu"</span>, <span class="fl">4</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>        <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html" class="external-link">map</a></span><span class="op">(</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/in_parallel.html" class="external-link">in_parallel</a></span><span class="op">(</span>\<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu">oom_task</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, oom_task <span class="op">=</span> <span class="va">oom_task</span><span class="op">)</span><span class="op">)</span></span>
<span>      <span class="va">results</span></span>
<span>    <span class="op">}</span>,</span>
<span>    times <span class="op">=</span> <span class="fl">5L</span>,</span>
<span>    unit <span class="op">=</span> <span class="st">"seconds"</span></span>
<span>  <span class="op">)</span></span>
<span>  <span class="va">summary_df</span> <span class="op">&lt;-</span> <span class="fu">summary_with_total</span><span class="op">(</span><span class="va">bench</span><span class="op">)</span></span>
<span>  <span class="fu">gpumux</span><span class="fu">::</span><span class="fu"><a href="../reference/gpu_daemons.html">gpu_daemons</a></span><span class="op">(</span>n_workers <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/Sys.sleep.html" class="external-link">Sys.sleep</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span></span>
<span>  <span class="va">summary_df</span></span>
<span><span class="op">}</span>, error <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">e</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/message.html" class="external-link">message</a></span><span class="op">(</span><span class="st">"Sequential GPU worker failed as expected."</span><span class="op">)</span></span>
<span>  <span class="fu">gpumux</span><span class="fu">::</span><span class="fu"><a href="../reference/gpu_daemons.html">gpu_daemons</a></span><span class="op">(</span>n_workers <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/Sys.sleep.html" class="external-link">Sys.sleep</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>expr <span class="op">=</span> <span class="st">"Sequential GPU - OOM"</span>, min <span class="op">=</span> <span class="cn">NA</span>, lq <span class="op">=</span> <span class="cn">NA</span>, mean <span class="op">=</span> <span class="cn">NA</span>, median <span class="op">=</span> <span class="cn">NA</span>, uq <span class="op">=</span> <span class="cn">NA</span>, max <span class="op">=</span> <span class="cn">NA</span>, neval <span class="op">=</span> <span class="fl">0</span>, total_time <span class="op">=</span> <span class="cn">NA</span><span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="co"># --- 4. Results (OOM) ---</span></span>
<span><span class="va">oom_benchmarks</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span></span>
<span>  <span class="va">persistent_oom_bench</span>,</span>
<span>  <span class="va">proxy_oom_bench</span>,</span>
<span>  <span class="va">sequential_oom_bench</span></span>
<span><span class="op">)</span></span>
<span><span class="fu">knitr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/knitr/man/kable.html" class="external-link">kable</a></span><span class="op">(</span><span class="va">oom_benchmarks</span>, caption <span class="op">=</span> <span class="st">"OOM Stability Test Results"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="conclusion-and-recommendations">Conclusion and Recommendations<a class="anchor" aria-label="anchor" href="#conclusion-and-recommendations"></a>
</h2>
<p>The three benchmarks tell a clear story about performance and
stability:</p>
<ul>
<li><p>For the <strong>GPU-Saturating Workload</strong>, sequential
execution is fastest. This is because each task is so demanding that it
needs the entire GPU. Running them in parallel creates resource
competition that slows the whole process down. This benchmark also
highlights the significant performance overhead of the
<code>proxy</code> worker, which is the price for its high degree of
stability.</p></li>
<li><p>For the <strong>Non-Saturating Workload</strong>, the
<code>persistent</code> parallel workers were significantly faster.
Because each task only used a fraction of the GPU’s power,
<code>gpumux</code> was able to run them truly concurrently, leading to
a significant throughput gain. This is the performance “sweet spot” for
the package.</p></li>
<li><p>For the <strong>Light Workload</strong>, running on the CPU is by
far the fastest. This demonstrates that for trivial tasks, the overhead
of sending the task to any kind of worker (even a persistent one) is
much greater than the execution time of the task itself.</p></li>
</ul>
<div class="section level3">
<h3 id="key-takeaways">Key Takeaways:<a class="anchor" aria-label="anchor" href="#key-takeaways"></a>
</h3>
<ul>
<li><p><strong><code>gpumux</code> shines when your tasks don’t saturate
the GPU.</strong> The main performance benefit comes from using the
GPU’s spare capacity to run multiple tasks at once.</p></li>
<li><p><strong><code>gpumux</code> provides critical resource
management.</strong> As seen with the sequential benchmark, running GPU
tasks in the main R session can lead to memory leaks.
<code>gpumux</code> solves this by isolating tasks in worker processes,
guaranteeing cleanup.</p></li>
<li><p><strong>Choose your worker type wisely.</strong> The
<code>proxy</code> worker provides maximum stability at the cost of
performance. The <code>persistent</code> worker provides maximum
performance but requires tasks to be well-behaved. For very small tasks,
the overhead of any worker type can be substantial.</p></li>
<li><p><strong>Know your workload.</strong> Before parallelizing,
understand if your tasks are heavy enough to saturate your hardware, if
they have idle periods, or if they are trivial. The
<code>nvidia-smi</code> command line tool is a great way to observe GPU
utilization during a single task run.</p></li>
</ul>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by First Last.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
